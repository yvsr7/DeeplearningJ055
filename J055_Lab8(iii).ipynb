{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "J055_Lab8(iii).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yvsr7/DeeplearningJ055/blob/master/J055_Lab8(iii).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZX8anbsht7g",
        "colab_type": "text"
      },
      "source": [
        "#Usage of loss functions\n",
        "\n",
        "A loss function (or objective function, or optimization score function) is one of the two parameters required to compile a model:\n",
        "\n",
        "```\n",
        "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
        "\n",
        "from keras import losses\n",
        "model.compile(loss=losses.mean_squared_error, optimizer='sgd')\n",
        "```\n",
        "\n",
        "You can either pass the name of an existing loss function, or pass a TensorFlow/Theano symbolic function that returns a scalar for each data-point and takes the following two arguments:\n",
        "\n",
        "1. y_true: True labels. TensorFlow/Theano tensor.\n",
        "2. y_pred: Predictions. TensorFlow/Theano tensor of the same shape as y_true.\n",
        "\n",
        "The actual optimized objective is the mean of the output array across all datapoints."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJkG-1OvheZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Categorically encode labels\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='elu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='elu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N52J4-gdiJSF",
        "colab_type": "text"
      },
      "source": [
        "#mean_squared_error\n",
        "\n",
        "keras.losses.mean_squared_error(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX0QPq4UiMSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='mean_squared_error',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEnK0HIRih01",
        "colab_type": "text"
      },
      "source": [
        "#mean_absolute_error\n",
        "\n",
        "keras.losses.mean_absolute_error(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJiGk6rmikKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='mean_absolute_error',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zCL32z2iohf",
        "colab_type": "text"
      },
      "source": [
        "#mean_absolute_percentage_error\n",
        "\n",
        "keras.losses.mean_absolute_percentage_error(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbVaaKZ8iruw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='mean_absolute_percentage_error',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDT2uAtfiuXH",
        "colab_type": "text"
      },
      "source": [
        "#mean_squared_logarithmic_error\n",
        "\n",
        "keras.losses.mean_squared_logarithmic_error(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tbm0lJwNixJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='mean_squared_logarithmic_error',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLY0Km_mi0PA",
        "colab_type": "text"
      },
      "source": [
        "#squared_hinge\n",
        "\n",
        "keras.losses.squared_hinge(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXoHk504i2e7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='squared_hinge',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hc5-jeei5PL",
        "colab_type": "text"
      },
      "source": [
        "#hinge\n",
        "\n",
        "keras.losses.hinge(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkbwuZ5li7oL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='hinge',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRoSjzqNjCwi",
        "colab_type": "text"
      },
      "source": [
        "#categorical_hinge\n",
        "\n",
        "keras.losses.categorical_hinge(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOrswDfMjF__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_hinge',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF0cEwoxjIXn",
        "colab_type": "text"
      },
      "source": [
        "#logcosh\n",
        "\n",
        "keras.losses.logcosh(y_true, y_pred)\n",
        "\n",
        "Logarithm of the hyperbolic cosine of the prediction error.\n",
        "\n",
        "log(cosh(x)) is approximately equal to (x ** 2) / 2 for small x and to abs(x) - log(2) for large x. This means that 'logcosh' works mostly like the mean squared error, but will not be so strongly affected by the occasional wildly incorrect prediction.\n",
        "\n",
        "##Arguments\n",
        "\n",
        "1. y_true: tensor of true targets.\n",
        "2. y_pred: tensor of predicted targets.\n",
        "\n",
        "##Returns\n",
        "\n",
        "1. Tensor with one scalar loss entry per sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4A7M01bjLap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='logcosh',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ0bv-eXjbXu",
        "colab_type": "text"
      },
      "source": [
        "#categorical_crossentropy\n",
        "\n",
        "keras.losses.categorical_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-XrpX7Ajd_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2hMi0U5jk4d",
        "colab_type": "text"
      },
      "source": [
        "#binary_crossentropy\n",
        "\n",
        "keras.losses.binary_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDLqW8otjnUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stvo_lw6jqcT",
        "colab_type": "text"
      },
      "source": [
        "#kullback_leibler_divergence\n",
        "\n",
        "keras.losses.kullback_leibler_divergence(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6MTeFaHjs4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='kullback_leibler_divergence',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co28pTxijuyE",
        "colab_type": "text"
      },
      "source": [
        "#poisson\n",
        "\n",
        "keras.losses.poisson(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7uvZNh_jxXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='poisson',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzJ8kS6Mj1iS",
        "colab_type": "text"
      },
      "source": [
        "#cosine_proximity\n",
        "\n",
        "keras.losses.cosine_proximity(y_true, y_pred, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgC8iO8Lj4Ie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='cosine_proximity',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waArOrH6BVCW",
        "colab_type": "text"
      },
      "source": [
        "Accuracies:\n",
        "\n",
        "\n",
        "*   mean_squared_error: \n",
        "Test loss: 0.0038390852939986196,\n",
        "Test accuracy: 0.9767\n",
        "*   mean_absolute_error:\n",
        "Test loss: 0.003613635207689349,\n",
        "Test accuracy: 0.9817\n",
        "*   mean_absolute_percentage_error:\n",
        "Test loss: 2194155.622003232,\n",
        "Test accuracy: 0.9786\n",
        "*   mean_squared_logarithmic_error:\n",
        "Test loss: 0.0018166392609879549,\n",
        "Test accuracy: 0.9803\n",
        "*   squared_hinge:\n",
        "Test loss: 0.9018693086624145,\n",
        "Test accuracy: 0.9802\n",
        "*   hinge:\n",
        "Test loss: 0.901867834854126,\n",
        "Test accuracy: 0.9812\n",
        "*   categorical_hinge:\n",
        "Test loss: 0.035601150780541276,\n",
        "Test accuracy: 0.9822\n",
        "*   logcosh:\n",
        "Test loss: 0.0014074075525470824,\n",
        "Test accuracy: 0.983\n",
        "*   categorical_crossentropy:\n",
        "Test loss: 0.2121463617329422,\n",
        "Test accuracy: 0.9822\n",
        "*   binary_crossentropy:\n",
        "Test loss: 0.04173960271100446,\n",
        "Test accuracy: 0.996349995803833\n",
        "*   kullback_leibler_divergence:\n",
        "Test loss: 0.2343970054849151,\n",
        "Test accuracy: 0.98\n",
        "*   poisson:\n",
        "Test loss: 0.1216721463561058,\n",
        "Test accuracy: 0.9815\n",
        "*   cosine_proximity:\n",
        "Test loss: -0.9813515180587769,\n",
        "Test accuracy: 0.9809\n",
        "\n",
        "Since, while using Binary Cross entropy as a loss measure, we get the highest level of accuracy, we use binary cross entropy for all models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0X2fr_n5nWG",
        "colab_type": "text"
      },
      "source": [
        "#Thank you for completing this notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skkFmaYhGnuE",
        "colab_type": "text"
      },
      "source": [
        "##Fashion MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PootYLzdGlGa",
        "colab_type": "code",
        "outputId": "5ea34058-ffdc-4b8a-d167-95582e2f9354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "# Load data\n",
        "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
        "\n",
        "\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Categorically encode labels\n",
        "Y_train = to_categorical(Y_train, NUM_CLASSES)\n",
        "Y_test = to_categorical(Y_test, NUM_CLASSES)\n",
        "\n",
        "\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test))\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 5us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 11s 184us/step - loss: 0.0946 - acc: 0.9619 - val_loss: 0.0807 - val_acc: 0.9671\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0672 - acc: 0.9726 - val_loss: 0.0864 - val_acc: 0.9676\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0608 - acc: 0.9757 - val_loss: 0.0645 - val_acc: 0.9746\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0563 - acc: 0.9772 - val_loss: 0.0616 - val_acc: 0.9755\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0530 - acc: 0.9787 - val_loss: 0.0609 - val_acc: 0.9769\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0503 - acc: 0.9800 - val_loss: 0.0660 - val_acc: 0.9754\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0484 - acc: 0.9808 - val_loss: 0.0637 - val_acc: 0.9760\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0469 - acc: 0.9813 - val_loss: 0.0695 - val_acc: 0.9764\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0455 - acc: 0.9821 - val_loss: 0.0598 - val_acc: 0.9781\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0441 - acc: 0.9826 - val_loss: 0.0668 - val_acc: 0.9762\n",
            "Test loss: 0.06678689503818751\n",
            "Test accuracy: 0.9761800046920777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX6D-ym_G1Ue",
        "colab_type": "text"
      },
      "source": [
        "##CIFAR 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLeHFi5WG3Gc",
        "colab_type": "code",
        "outputId": "ecf9557f-5b01-4ef5-c14a-074985518db5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(Y_train, 10)\n",
        "Y_test =  to_categorical(Y_test, 10)\n",
        "\n",
        "#Model building\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072, )))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test))\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 3s 52us/step - loss: 0.4795 - acc: 0.8931 - val_loss: 0.2697 - val_acc: 0.9027\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 0.2689 - acc: 0.9024 - val_loss: 0.2608 - val_acc: 0.9031\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 0.2562 - acc: 0.9052 - val_loss: 0.2517 - val_acc: 0.9069\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 0.2471 - acc: 0.9075 - val_loss: 0.2588 - val_acc: 0.9035\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 0.2399 - acc: 0.9091 - val_loss: 0.2384 - val_acc: 0.9102\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 0.2349 - acc: 0.9109 - val_loss: 0.2427 - val_acc: 0.9083\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 0.2308 - acc: 0.9123 - val_loss: 0.2510 - val_acc: 0.9075\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 0.2267 - acc: 0.9132 - val_loss: 0.2432 - val_acc: 0.9098\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 0.2235 - acc: 0.9148 - val_loss: 0.2375 - val_acc: 0.9098\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 0.2196 - acc: 0.9159 - val_loss: 0.2567 - val_acc: 0.9067\n",
            "Test loss: 0.2566855202674866\n",
            "Test accuracy: 0.9067099834442138\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9njlwDmHEQM",
        "colab_type": "text"
      },
      "source": [
        "##CIFAR 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QigrApDGzU_",
        "colab_type": "code",
        "outputId": "8f90bfce-4f06-4458-d953-396e5860cb83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "from keras.datasets import cifar100\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar100.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(Y_train, 100)\n",
        "Y_test =  to_categorical(Y_test, 100)\n",
        "\n",
        "#Model building\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072, )))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "from keras import optimizers\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test))\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 4s 0us/step\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 3s 52us/step - loss: 0.0526 - acc: 0.9900 - val_loss: 0.0494 - val_acc: 0.9900\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 0.0477 - acc: 0.9900 - val_loss: 0.0470 - val_acc: 0.9900\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 0.0456 - acc: 0.9901 - val_loss: 0.0451 - val_acc: 0.9901\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 0.0441 - acc: 0.9901 - val_loss: 0.0453 - val_acc: 0.9901\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 0.0430 - acc: 0.9902 - val_loss: 0.0443 - val_acc: 0.9902\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 0.0421 - acc: 0.9902 - val_loss: 0.0442 - val_acc: 0.9902\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 0.0413 - acc: 0.9903 - val_loss: 0.0429 - val_acc: 0.9902\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 0.0407 - acc: 0.9903 - val_loss: 0.0440 - val_acc: 0.9901\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 0.0400 - acc: 0.9904 - val_loss: 0.0439 - val_acc: 0.9901\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 0.0394 - acc: 0.9905 - val_loss: 0.0450 - val_acc: 0.9900\n",
            "Test loss: 0.044990917378664015\n",
            "Test accuracy: 0.990018009185791\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}